{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab12_Deep_Learning_For_Image_Classification_hdf5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgkzKiunhbw0"
      },
      "source": [
        "# IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWNMJm1Ln-NC"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXkbUIboiV3G"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import h5py\n",
        "from google.colab import drive # Necessary to access data stored in google drive "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMdz1z0aiBSH"
      },
      "source": [
        "# DEFINITION OF DIRECTORIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmd2nIeijXr"
      },
      "source": [
        "The data will be stored in Google Drive, so that we can access it easily from Google Colab. Therefore, we must mount Google Drive and define the directories where the images are stored within Google Drive.\n",
        "\n",
        "We might load the images directly from the folders stored in Google Drive. However, Google Colab is very slow at doing this, thus creating a bottleneck. Therefore, we will load the images once directly into numpy tensors from an hdf5 file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxPGmzSiir8B"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# %% 0 - Definition of directories\n",
        "\n",
        "base_dir = '/content/gdrive/MyDrive/'\n",
        "\n",
        "with h5py.File(os.path.join(base_dir, \"cats_and_dogs_small.hdf5\"), \"r\") as file:\n",
        "\n",
        "  # print(file.items())\n",
        "\n",
        "  train_group = file.get('training')\n",
        "  # print(train_group.items())\n",
        "  train_images_aux = train_group.get('images')\n",
        "  train_images = train_images_aux[()]\n",
        "  train_images = train_images.astype(np.float64)\n",
        "  train_labels_aux = train_group.get('labels')\n",
        "  train_labels = train_labels_aux[()]\n",
        "\n",
        "  validation_group = file.get('validation')\n",
        "  # print(validation_group.items())\n",
        "  validation_images_aux = validation_group.get('images')\n",
        "  validation_images = validation_images_aux[()]\n",
        "  validation_images = validation_images.astype(np.float64)\n",
        "  validation_labels_aux = validation_group.get('labels')\n",
        "  validation_labels = validation_labels_aux[()]\n",
        "\n",
        "  test_group = file.get('test')\n",
        "  # print(test_group.items())\n",
        "  test_images_aux = test_group.get('images')\n",
        "  test_images = test_images_aux[()]\n",
        "  test_images = test_images.astype(np.float64)\n",
        "  test_labels_aux = test_group.get('labels')\n",
        "  test_labels = test_labels_aux[()]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnvpXI33iDLD"
      },
      "source": [
        "# 1. TRAINING FROM SCRATCH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys-rAALEnEx3"
      },
      "source": [
        "### 1.1. - Building the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlpJw9xHnbAz"
      },
      "source": [
        "The input images have a size 150 × 150 (a somewhat arbitrary choice), you end\n",
        "up with feature maps of size 7 × 7 just before the Flatten layer.\n",
        "\n",
        "NOTE: The depth of the feature maps progressively increases in the network\n",
        "(from 32 to 128), whereas the size of the feature maps decreases (from\n",
        "148 × 148 to 7 × 7). This is a pattern you’ll see in almost all convnets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQupbbA4nDxQ"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8XHKL4uoN2l"
      },
      "source": [
        "Display the architecture of the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o70G3PYzoNkV"
      },
      "source": [
        "print('\\n\\n**********************************************************')\n",
        "print('**** ARCHITECTURE OF THE CONVOLUTIONAL NEURAL NETWORK ****')\n",
        "print('**********************************************************\\n')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0F5CeFiojTi"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8bkDjFJojGx"
      },
      "source": [
        "model.compile(optimizer='Adam', metrics=['accuracy'], loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m70sGy5cotGV"
      },
      "source": [
        "### 1.2. - Preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ushnHyWwos8d"
      },
      "source": [
        "As you know by now, data should be formatted into appropriately\n",
        "preprocessed floating- point tensors before being fed into the network.\n",
        "Currently, the data sits on tensors loaded from a hdf5 file, so the steps for getting it into the network are roughly as follows:\n",
        "         \n",
        "\n",
        "1.   Use the images from the loaded tensors.\n",
        "2.   Convert these into floating-point tensors.\n",
        "3.   Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UpaOEAqpJGL"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_gen = train_datagen.flow(x=np.array(train_images), y=train_labels, batch_size=20)\n",
        "\n",
        "validation_gen = train_datagen.flow(x=np.array(validation_images), batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x3Pc0ZepPW8"
      },
      "source": [
        "Showing the first image from the train generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfPKBlqSpRN2"
      },
      "source": [
        "x_batch, ybatch = next(train_gen)\n",
        "\n",
        "img = x_batch[0]\n",
        "plt.figure()\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEtcSvQ2qCBi"
      },
      "source": [
        "### 1.3. - Fitting the model using a batch generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an1HKTs0qbv6"
      },
      "source": [
        "fname_model_from_scratch = os.path.join(base_dir, 'models',\n",
        "                                        'a_cats_vs_dogs_small_from_scratch.h5')\n",
        "\n",
        "history = model.fit(train_gen, steps_per_epoch=10, epochs=30, verbose=1, validation_data=validation_gen, validation_steps=10)\n",
        "  \n",
        "# Saving the model (Good practice to use it in the future)\n",
        "print('\\n\\nSaving model to file.')\n",
        "model.save(fname_model_from_scratch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1fvpL-q1ld"
      },
      "source": [
        "Displaying curves of loss and accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71l3H6-Tq5ma"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training ac')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaYX_9JVqMv0"
      },
      "source": [
        "### 1.4. - Prediction of the instances in the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUa3H-psrEUF"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "test_generator = test_datagen.flow(x = np.array(test_images), batch_size=1)\n",
        "\n",
        "nb_test_samples = len(test_labels)\n",
        "\n",
        "predicted_probabilities = model.predict()\n",
        "\n",
        "predicted_classes_bin = predicted_probabilities >= 0.5\n",
        "predicted_classes_bin = predicted_classes_bin.astype('int32').reshape((1000,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw1ScVmbrGi7"
      },
      "source": [
        "Print the performance metrics (i.e. accuracy and Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NCxQXqXrJFE"
      },
      "source": [
        "accuracy = accuracy_score(test_labels, predicted_classes_bin)\n",
        "print()\n",
        "print('Accuracy (Convolutional Neural Network)= {}'.format(accuracy))\n",
        "cm = confusion_matrix(predicted_classes_bin, test_labels)\n",
        "print('Confusion Matrix with Convolutional Neural Network: ')\n",
        "print(cm)\n",
        "print('***********************************************')\n",
        "print('***********************************************')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx2Bnl7ZiHjb"
      },
      "source": [
        "# 2. USING DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzFPKoOvZO3G"
      },
      "source": [
        "### 2.1. - Setting up the image generator which performs data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtqtMyLPZjbY"
      },
      "source": [
        "Setting up a data augmentation configuration via ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5pfL_1cYVLR"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "  rotation_range = 40,\n",
        "  horizontal_flip=True,\n",
        "  width_shift_range = 0.2,\n",
        "  height_shift_range = 0.2,\n",
        "  shear_range = 0.2,\n",
        "  rescale=1./ 255,\n",
        "  zoom_range = 0.2,\n",
        "  vertical_flip = True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw5CtzU4aLv0"
      },
      "source": [
        "Displaying some randomly augmented images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5E8rSgcaA0e"
      },
      "source": [
        "img = train_images[23,:,:,:]\n",
        "\n",
        "img2 = image.img_to_array(img)\n",
        "img2 = img2.reshape((1,) + img2.shape)\n",
        "\n",
        "i = 0\n",
        "for batch in train_datagen.flow(img2, batch_size=1):\n",
        "  plt.figure(1)\n",
        "  imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
        "  i += 1\n",
        "  if i % 4 == 0:\n",
        "    break\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4WJVnwKaZvH"
      },
      "source": [
        "### 2.2. - Defining network architecture adding Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9naKUN1OakxH"
      },
      "source": [
        "If you train a new network using this data-augmentation configuration, the network will never see the same input twice. But the inputs it sees are still heavily intercorrelated, because they come from a small number of original images — you can’t produce new information, you can only remix existing information. As such, this may not be enough to completely get rid of overfitting. To further fight overfitting, you’ll also add a **Dropout** layer to your model, right before the densely connected classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-RqCPdNa_7H"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(64,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Conv2D(128,(3,3),activation='relu',input_shape=(150,150,1)))\n",
        "model.add(layers.MaxPool2D(2,2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(rate = 0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3akuA4DKbRiR"
      },
      "source": [
        "Display the architecture of the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUf_FUyrbEjk"
      },
      "source": [
        "print('\\n\\n**********************************************************')\n",
        "print('**** ARCHITECTURE OF THE CONVOLUTIONAL NEURAL NETWORK ****')\n",
        "print('**********************************************************\\n')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WytwESqxbVR0"
      },
      "source": [
        "Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSAtnk6vbGXt"
      },
      "source": [
        "model.compile(optimizer='Adam', metrics=['accuracy'], loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7u-s5TiYj4t"
      },
      "source": [
        "### 2.3. - Training the network using the data-augmentation generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcO8VHu1YrCN"
      },
      "source": [
        "fname_model_data_augment = os.path.join(base_dir, 'models',\n",
        "                                        'b_cats_vs_dogs_small_data_augment.h5')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "  \n",
        "train_generator = train_datagen.flow(x = np.array(train_images), y = train_labels, batch_size = 20)\n",
        "\n",
        "validation_generator = train_datagen.flow(x=np.array(validation_images), batch_size=20)\n",
        "\n",
        "history = model.fit(train_generator, steps_per_epoch=100, epochs=100, verbose=1, validation_data=validation_generator, validation_steps=10)\n",
        "  \n",
        "# Saving the model\n",
        "print('\\n\\nSaving model to file.')\n",
        "model.save(fname_model_data_augment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eYmptaPbqLJ"
      },
      "source": [
        "Displaying curves of loss and accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz4DHpxmbg38"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training ac')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0EkwbGybgko"
      },
      "source": [
        "### 2.4. - Prediction of the instances in the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_3YsArYaJgs"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "test_generator = test_datagen.flow(x=np.array(test_images), batch_size = 1)\n",
        "\n",
        "nb_test_samples = len(test_labels)\n",
        "\n",
        "predicted_classes = model.predict(test_generator)\n",
        "\n",
        "predicted_classes_bin = predicted_classes >= 0.5\n",
        "predicted_classes_bin = predicted_classes_bin.astype('int32').reshape((1000,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_MSPJloaACp"
      },
      "source": [
        "Print the performance metrics (i.e. accuracy and Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiDk8gW-cndf"
      },
      "source": [
        "accuracy = accuracy_score(test_labels, predicted_classes_bin)\n",
        "print()\n",
        "print('Accuracy (Convolutional Neural Network)= {}'.format(accuracy))\n",
        "cm = confusion_matrix(predicted_classes_bin, test_labels)\n",
        "print('Confusion Matrix with Convolutional Neural Network: ')\n",
        "print(cm)\n",
        "print('***********************************************')\n",
        "print('***********************************************')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohgF2xDust2O"
      },
      "source": [
        "# 3. USING A PRE-TRAINED MODEL FOR FEATURE EXTRACTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUxzbSxQpz2Q"
      },
      "source": [
        "Defining function for extracting features using a given convolutional base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZv15p-fplAr"
      },
      "source": [
        "def extract_features(x_images, y_labels, sample_count, datagen, batch_size, conv_base):\n",
        "  features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
        "  labels = np.zeros(shape=(sample_count,))\n",
        "  \n",
        "  generator = datagen.flow(\n",
        "      x=x_images,\n",
        "      y=y_labels,\n",
        "      batch_size=batch_size)\n",
        "\n",
        "  i = 0\n",
        "  for inputs_batch, labels_batch in generator:\n",
        "    features_batch = conv_base.predict(inputs_batch, verbose=1)\n",
        "    features[i * batch_size:(i+1) * batch_size] = features_batch\n",
        "    labels[i * batch_size:(i+1) * batch_size] = labels_batch\n",
        "    i += 1\n",
        "    if i * batch_size >= sample_count:\n",
        "      break\n",
        "  \n",
        "  return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZxjyxYep8TX"
      },
      "source": [
        "### 3.1. - Instantiating the convolutional base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aECZ88tPqExJ"
      },
      "source": [
        "We will use a pretrained VGG16 Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za69pqiGp8te"
      },
      "source": [
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(150, 150, 3))\n",
        "\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAOeMeDdqQ8x"
      },
      "source": [
        "### 3.2. - Fast Feature Extraction without data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWRNfG1QraTQ"
      },
      "source": [
        "Defining names for pickle files to save features into (or load them from)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgwJKoXorg6K"
      },
      "source": [
        "fname_feats_train = os.path.join(base_dir, 'models',\n",
        "                                 'c_cats_vs_dogs_small_train_feats.pkl')\n",
        "fname_feats_valid = os.path.join(base_dir, 'models',\n",
        "                                 'c_cats_vs_dogs_small_valid_feats.pkl')\n",
        "fname_feats_test = os.path.join(base_dir, 'models',\n",
        "                                'c_cats_vs_dogs_small_test_feats.pkl')\n",
        "fname_labels_train = os.path.join(base_dir, 'models',\n",
        "                                  'c_cats_vs_dogs_small_train_labels.pkl')\n",
        "fname_labels_valid = os.path.join(base_dir, 'models',\n",
        "                                  'c_cats_vs_dogs_small_valid_labels.pkl')\n",
        "fname_labels_test = os.path.join(base_dir, 'models',\n",
        "                                 'c_cats_vs_dogs_small_test_labels.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD9fBOwgqWn1"
      },
      "source": [
        "Running the convolutional base over your dataset, recording its output to a Numpy array on disk, and then using this data as input to a standalone, densely\n",
        "connected classifier similar to those you saw in the previous lab. This solution is fast and cheap to run, because it only requires running the\n",
        "convolutional base once for every input image, and the convolutional base is by\n",
        "far the most expensive part of the pipeline. But for the same reason, this technique won’t allow you to use data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzA-8NQ-qqav"
      },
      "source": [
        "datagen = ImageDataGenerator(rescale=1/255)\n",
        "batch_size = 20\n",
        "\n",
        "num_samples_train = train_images.shape[0]\n",
        "num_samples_valid = validation_images.shape[0]\n",
        "num_samples_test = test_images.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDqWG5S3qy3X"
      },
      "source": [
        "Extract features from training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxQAeyw0q4Bd"
      },
      "source": [
        "if not os.path.exists(fname_feats_train):\n",
        "  train_features, train_labels = extract_features(train_images, train_labels, len(train_images), datagen, batch_size, conv_base)\n",
        "  train_features = np.reshape(\n",
        "      train_features,\n",
        "      (train_features.shape[0], np.prod(train_features.shape[1:4])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTaXyykVq0DB"
      },
      "source": [
        "Extract features from validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALnQPPEvrCnG"
      },
      "source": [
        "if not os.path.exists(fname_feats_valid):\n",
        "\n",
        "  validation_feats, validation_labels = extract_features(validation_images, validation_labels, len(validation_images), datagen, batch_size, conv_base)\n",
        "  validation_feats = np.reshape(\n",
        "      validation_feats,\n",
        "      (validation_feats.shape[0], np.prod(validation_feats.shape[1:4])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rzuDclKq29C"
      },
      "source": [
        "Extract features from test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aPhzE7irLui"
      },
      "source": [
        "if not os.path.exists(fname_feats_test):\n",
        "\n",
        "  test_features, test_labels = extract_features(test_images, test_labels, len(test_images), datagen, batch_size, conv_base)\n",
        "  test_features = np.reshape(\n",
        "      test_features,\n",
        "      (test_features.shape[0], np.prod(test_features.shape[1:4])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSd7_Xk8r6gh"
      },
      "source": [
        "Saving features to pickle files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMzFW1IAr7oe"
      },
      "source": [
        "if not os.path.exists(fname_feats_train):\n",
        "  output_train = open(fname_feats_train, 'wb')\n",
        "  output_valid = open(fname_feats_valid, 'wb')\n",
        "  output_test = open(fname_feats_test, 'wb')\n",
        "  output_train_labels = open(fname_labels_train, 'wb')\n",
        "  output_valid_labels = open(fname_labels_valid, 'wb')\n",
        "  output_test_labels = open(fname_labels_test, 'wb')\n",
        "  pickle.dump(train_features, output_train)\n",
        "  pickle.dump(validation_feats, output_valid)\n",
        "  pickle.dump(test_features, output_test)\n",
        "  pickle.dump(train_labels, output_train_labels)\n",
        "  pickle.dump(validation_labels, output_valid_labels)\n",
        "  pickle.dump(test_labels, output_test_labels)\n",
        "  output_train.close()\n",
        "  output_valid.close()\n",
        "  output_test.close()\n",
        "  output_train_labels.close()\n",
        "  output_valid_labels.close()\n",
        "  output_test_labels.close()\n",
        "\n",
        "else:\n",
        "  input_train = open(fname_feats_train, 'rb')\n",
        "  input_valid = open(fname_feats_valid, 'rb')\n",
        "  input_test = open(fname_feats_test, 'rb')\n",
        "  input_train_labels = open(fname_labels_train, 'rb')\n",
        "  input_valid_labels = open(fname_labels_valid, 'rb')\n",
        "  input_test_labels = open(fname_labels_test, 'rb')\n",
        "  train_features = pickle.load(input_train)\n",
        "  validation_feats = pickle.load(input_valid)\n",
        "  test_features = pickle.load(input_test)\n",
        "  train_labels = pickle.load(input_train_labels)\n",
        "  validation_labels = pickle.load(input_valid_labels)\n",
        "  test_labels = pickle.load(input_test_labels)\n",
        "  input_train.close()\n",
        "  input_valid.close()\n",
        "  input_test.close()\n",
        "  input_train_labels.close()\n",
        "  input_valid_labels.close()\n",
        "  input_test_labels.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOm5MOEdsPX-"
      },
      "source": [
        "### 3.3. - Define and train a densly connected neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OX10hDsV-z"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(rate = 0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer='RMSProp', metrics=['accuracy'], loss='binary_crossentropy')\n",
        "\n",
        "history = model.fit(train_features, steps_per_epoch=100, epochs = 30, verbose = 1, validation_data = validation_feats, validation_steps = 100)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW9JMlCCsbNo"
      },
      "source": [
        "Displaying curves of loss and accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krLKq9-asb41"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training ac')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78LqMh2hsepY"
      },
      "source": [
        "### 3.4. - Prediction of the instances in the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adqNZfBRskIN"
      },
      "source": [
        "predicted_classes = model.predict(test_features)\n",
        "\n",
        "predicted_classes_bin = predicted_classes >= 0.5\n",
        "predicted_classes_bin = predicted_classes_bin.astype('int32').reshape((1000,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO5mzzwUsrob"
      },
      "source": [
        "Print the performance metrics (i.e. accuracy and Confusion Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzJ50C9jspe5"
      },
      "source": [
        "accuracy = accuracy_score(test_labels, predicted_classes_bin)\n",
        "print()\n",
        "print('Accuracy (Convolutional Neural Network)= {}'.format(accuracy))\n",
        "cm = confusion_matrix(predicted_classes_bin, test_labels)\n",
        "print('Confusion Matrix with Convolutional Neural Network: ')\n",
        "print(cm)\n",
        "print('***********************************************')\n",
        "print('***********************************************')\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}